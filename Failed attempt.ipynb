{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5deYhThLWFW"
      },
      "source": [
        "I must first upload my kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gZkJ4gZGF6ND"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY01ncY3DcP3",
        "outputId": "8bc75ef3-6ec5-4d3c-f847-55f4965e619c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading guardian-news-articles.zip to /content\n",
            "100% 277M/278M [00:14<00:00, 23.6MB/s]\n",
            "100% 278M/278M [00:14<00:00, 19.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d adityakharosekar2/guardian-news-articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2lknXASGMlM",
        "outputId": "daee763c-e9a7-4ec0-d6e4-f68311ca86c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_hub) (1.22.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow_hub) (3.20.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XRdcgKGaGTZt"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, SimpleRNN, Dense, Conv1D, MaxPooling1D\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NxEDiVHjGmB4"
      },
      "outputs": [],
      "source": [
        "# Specify the path to the zip file\n",
        "zip_file_path = '/content/guardian-news-articles.zip'\n",
        "\n",
        "# Open the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    # Extract all the files in the zip file to a folder\n",
        "    zip_ref.extractall('/content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "g8b0moqEGWje"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess data\n",
        "data = pd.read_csv('/content/guardian_articles.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "wOrQ92ivSq2V",
        "outputId": "d81edec7-e346-43d8-9139-b8c293bcb1db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               article_id     sectionName  \\\n",
              "0       us-news/2016/jan/31/iowa-caucus-underdog-candi...         US news   \n",
              "1       us-news/2016/jan/31/iowa-caucus-worlds-most-pa...         US news   \n",
              "2       world/2016/jan/31/tanzania-britsh-helicopter-p...      World news   \n",
              "3       football/2016/jan/31/late-winner-gets-usa-off-...        Football   \n",
              "4       football/2016/jan/31/blackburn-paul-lambert-ox...        Football   \n",
              "...                                                   ...             ...   \n",
              "149834  world/2022/jun/21/marble-head-of-hercules-pull...      World news   \n",
              "149835  music/2022/jun/22/i-got-sick-of-talking-about-...           Music   \n",
              "149836  australia-news/2022/jun/22/the-small-town-with...  Australia news   \n",
              "149837  australia-news/2022/jun/22/power-to-ban-citize...  Australia news   \n",
              "149838  australia-news/2022/jun/22/liberal-mps-say-pet...  Australia news   \n",
              "\n",
              "                                                 webTitle  \\\n",
              "0       Iowa underdogs put on brave faces despite all ...   \n",
              "1       Iowa caucus: hologram eagle and Jesus star on ...   \n",
              "2       British pilot in Tanzania 'manoeuvred ​to save...   \n",
              "3       USA 3-2 Iceland | International friendly match...   \n",
              "4       Reinvigorated Paul Lambert reflects after impr...   \n",
              "...                                                   ...   \n",
              "149834  Marble head of Hercules pulled up from Roman s...   \n",
              "149835  ‘I got sick of talking about myself’: Spacey J...   \n",
              "149836  The small town with a big potato that inspired...   \n",
              "149837  Power to ban citizens from re-entering Austral...   \n",
              "149838  Liberal MPs say Peter Dutton should let party ...   \n",
              "\n",
              "                                                   webUrl  \\\n",
              "0       https://www.theguardian.com/us-news/2016/jan/3...   \n",
              "1       https://www.theguardian.com/us-news/2016/jan/3...   \n",
              "2       https://www.theguardian.com/world/2016/jan/31/...   \n",
              "3       https://www.theguardian.com/football/2016/jan/...   \n",
              "4       https://www.theguardian.com/football/2016/jan/...   \n",
              "...                                                   ...   \n",
              "149834  https://www.theguardian.com/world/2022/jun/21/...   \n",
              "149835  https://www.theguardian.com/music/2022/jun/22/...   \n",
              "149836  https://www.theguardian.com/australia-news/202...   \n",
              "149837  https://www.theguardian.com/australia-news/202...   \n",
              "149838  https://www.theguardian.com/australia-news/202...   \n",
              "\n",
              "                                              bodyContent  \\\n",
              "0       As polling day looms and the cameras turn only...   \n",
              "1       In Des Moines on Sunday, the Guardian was give...   \n",
              "2       A British pilot who was shot dead by an elepha...   \n",
              "3       USA took a step toward shaking off the ghosts ...   \n",
              "4       The clean-shaven, spectacle free and suspiciou...   \n",
              "...                                                   ...   \n",
              "149834  For archaeologists, it’s the underwater find t...   \n",
              "149835  From under a mop of curls, Caleb Harper – Spac...   \n",
              "149836  Robertson is a small, pretty town perched on t...   \n",
              "149837  A high court decision striking down the home a...   \n",
              "149838  Liberal MPs are urging Peter Dutton to let the...   \n",
              "\n",
              "          webPublicationDate      id  \n",
              "0       2016-01-31T23:53:37Z       1  \n",
              "1       2016-01-31T23:46:28Z       2  \n",
              "2       2016-01-31T23:43:48Z       3  \n",
              "3       2016-01-31T23:30:49Z       4  \n",
              "4       2016-01-31T22:30:10Z       5  \n",
              "...                      ...     ...  \n",
              "149834  2022-06-21T17:31:32Z  149835  \n",
              "149835  2022-06-21T17:30:09Z  149836  \n",
              "149836  2022-06-21T17:30:09Z  149837  \n",
              "149837  2022-06-21T17:30:08Z  149838  \n",
              "149838  2022-06-21T17:30:08Z  149839  \n",
              "\n",
              "[149839 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7064e782-21e3-43e4-ba41-9d634a3bc52b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_id</th>\n",
              "      <th>sectionName</th>\n",
              "      <th>webTitle</th>\n",
              "      <th>webUrl</th>\n",
              "      <th>bodyContent</th>\n",
              "      <th>webPublicationDate</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>us-news/2016/jan/31/iowa-caucus-underdog-candi...</td>\n",
              "      <td>US news</td>\n",
              "      <td>Iowa underdogs put on brave faces despite all ...</td>\n",
              "      <td>https://www.theguardian.com/us-news/2016/jan/3...</td>\n",
              "      <td>As polling day looms and the cameras turn only...</td>\n",
              "      <td>2016-01-31T23:53:37Z</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>us-news/2016/jan/31/iowa-caucus-worlds-most-pa...</td>\n",
              "      <td>US news</td>\n",
              "      <td>Iowa caucus: hologram eagle and Jesus star on ...</td>\n",
              "      <td>https://www.theguardian.com/us-news/2016/jan/3...</td>\n",
              "      <td>In Des Moines on Sunday, the Guardian was give...</td>\n",
              "      <td>2016-01-31T23:46:28Z</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>world/2016/jan/31/tanzania-britsh-helicopter-p...</td>\n",
              "      <td>World news</td>\n",
              "      <td>British pilot in Tanzania 'manoeuvred ​to save...</td>\n",
              "      <td>https://www.theguardian.com/world/2016/jan/31/...</td>\n",
              "      <td>A British pilot who was shot dead by an elepha...</td>\n",
              "      <td>2016-01-31T23:43:48Z</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>football/2016/jan/31/late-winner-gets-usa-off-...</td>\n",
              "      <td>Football</td>\n",
              "      <td>USA 3-2 Iceland | International friendly match...</td>\n",
              "      <td>https://www.theguardian.com/football/2016/jan/...</td>\n",
              "      <td>USA took a step toward shaking off the ghosts ...</td>\n",
              "      <td>2016-01-31T23:30:49Z</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>football/2016/jan/31/blackburn-paul-lambert-ox...</td>\n",
              "      <td>Football</td>\n",
              "      <td>Reinvigorated Paul Lambert reflects after impr...</td>\n",
              "      <td>https://www.theguardian.com/football/2016/jan/...</td>\n",
              "      <td>The clean-shaven, spectacle free and suspiciou...</td>\n",
              "      <td>2016-01-31T22:30:10Z</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149834</th>\n",
              "      <td>world/2022/jun/21/marble-head-of-hercules-pull...</td>\n",
              "      <td>World news</td>\n",
              "      <td>Marble head of Hercules pulled up from Roman s...</td>\n",
              "      <td>https://www.theguardian.com/world/2022/jun/21/...</td>\n",
              "      <td>For archaeologists, it’s the underwater find t...</td>\n",
              "      <td>2022-06-21T17:31:32Z</td>\n",
              "      <td>149835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149835</th>\n",
              "      <td>music/2022/jun/22/i-got-sick-of-talking-about-...</td>\n",
              "      <td>Music</td>\n",
              "      <td>‘I got sick of talking about myself’: Spacey J...</td>\n",
              "      <td>https://www.theguardian.com/music/2022/jun/22/...</td>\n",
              "      <td>From under a mop of curls, Caleb Harper – Spac...</td>\n",
              "      <td>2022-06-21T17:30:09Z</td>\n",
              "      <td>149836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149836</th>\n",
              "      <td>australia-news/2022/jun/22/the-small-town-with...</td>\n",
              "      <td>Australia news</td>\n",
              "      <td>The small town with a big potato that inspired...</td>\n",
              "      <td>https://www.theguardian.com/australia-news/202...</td>\n",
              "      <td>Robertson is a small, pretty town perched on t...</td>\n",
              "      <td>2022-06-21T17:30:09Z</td>\n",
              "      <td>149837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149837</th>\n",
              "      <td>australia-news/2022/jun/22/power-to-ban-citize...</td>\n",
              "      <td>Australia news</td>\n",
              "      <td>Power to ban citizens from re-entering Austral...</td>\n",
              "      <td>https://www.theguardian.com/australia-news/202...</td>\n",
              "      <td>A high court decision striking down the home a...</td>\n",
              "      <td>2022-06-21T17:30:08Z</td>\n",
              "      <td>149838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149838</th>\n",
              "      <td>australia-news/2022/jun/22/liberal-mps-say-pet...</td>\n",
              "      <td>Australia news</td>\n",
              "      <td>Liberal MPs say Peter Dutton should let party ...</td>\n",
              "      <td>https://www.theguardian.com/australia-news/202...</td>\n",
              "      <td>Liberal MPs are urging Peter Dutton to let the...</td>\n",
              "      <td>2022-06-21T17:30:08Z</td>\n",
              "      <td>149839</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>149839 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7064e782-21e3-43e4-ba41-9d634a3bc52b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7064e782-21e3-43e4-ba41-9d634a3bc52b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7064e782-21e3-43e4-ba41-9d634a3bc52b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzPuh2RjKWXL",
        "outputId": "c065850b-16fd-422c-dbfd-c2599fdb102b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 10410\n",
            "Validation samples: 1488\n",
            "Test samples: 2975\n"
          ]
        }
      ],
      "source": [
        "data = data[['sectionName', 'bodyContent']]  # Keep only the relevant columns\n",
        "data = data.dropna()  # Remove rows with missing values\n",
        "# Select a random 10%-20% portion of the dataset\n",
        "data_sample = data.sample(frac=0.1, random_state=42)\n",
        "\n",
        "# Split the dataset into training (80%), validation (10%), and test (10%) sets\n",
        "train, test = train_test_split(data_sample, test_size=0.2, random_state=42)\n",
        "train, val = train_test_split(train, test_size=0.125, random_state=42)\n",
        "\n",
        "print(\"Training samples:\", len(train))\n",
        "print(\"Validation samples:\", len(val))\n",
        "print(\"Test samples:\", len(test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Ik2L7_dQS2Mn",
        "outputId": "016f5c34-44a1-4817-9543-ebc7fa4f8ddb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               sectionName                                        bodyContent\n",
              "97494           World news  Scott Morrison will urge G20 leaders to fund r...\n",
              "69852   Global development  The fragrant jasmine rice growing on the left ...\n",
              "74324              UK news  An MI6 officer was discovered to have child se...\n",
              "51220                Sport  The greatest on-field scandal in the history o...\n",
              "41914             Business  Let’s hope António Horta-Osório is right. The ...\n",
              "...                    ...                                                ...\n",
              "89785              UK news  The jury at Preston crown court has been sent ...\n",
              "83369             Politics  A petition calling on the government not to pr...\n",
              "100105             Opinion  It has been both a curse and a blessing for Ke...\n",
              "139951             Fashion  The opening of Paris haute couture fashion wee...\n",
              "60451           Technology  An advert describing a smartphone app as a “hi...\n",
              "\n",
              "[10410 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c70e396-4abd-4e72-a9d1-24db67f8723c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sectionName</th>\n",
              "      <th>bodyContent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>97494</th>\n",
              "      <td>World news</td>\n",
              "      <td>Scott Morrison will urge G20 leaders to fund r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69852</th>\n",
              "      <td>Global development</td>\n",
              "      <td>The fragrant jasmine rice growing on the left ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74324</th>\n",
              "      <td>UK news</td>\n",
              "      <td>An MI6 officer was discovered to have child se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51220</th>\n",
              "      <td>Sport</td>\n",
              "      <td>The greatest on-field scandal in the history o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41914</th>\n",
              "      <td>Business</td>\n",
              "      <td>Let’s hope António Horta-Osório is right. The ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89785</th>\n",
              "      <td>UK news</td>\n",
              "      <td>The jury at Preston crown court has been sent ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83369</th>\n",
              "      <td>Politics</td>\n",
              "      <td>A petition calling on the government not to pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100105</th>\n",
              "      <td>Opinion</td>\n",
              "      <td>It has been both a curse and a blessing for Ke...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139951</th>\n",
              "      <td>Fashion</td>\n",
              "      <td>The opening of Paris haute couture fashion wee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60451</th>\n",
              "      <td>Technology</td>\n",
              "      <td>An advert describing a smartphone app as a “hi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10410 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c70e396-4abd-4e72-a9d1-24db67f8723c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c70e396-4abd-4e72-a9d1-24db67f8723c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c70e396-4abd-4e72-a9d1-24db67f8723c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TgQ31ginKYlW"
      },
      "outputs": [],
      "source": [
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train['bodyContent'])\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(train['bodyContent'])\n",
        "X_val = tokenizer.texts_to_sequences(val['bodyContent'])\n",
        "X_test = tokenizer.texts_to_sequences(test['bodyContent'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0X3tdBWiKtKm"
      },
      "outputs": [],
      "source": [
        "# Pad the sequences\n",
        "max_length = 500\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=max_length, padding='post', truncating='post')\n",
        "X_val = pad_sequences(X_val, maxlen=max_length, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_length, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gDW5bctYKu-c"
      },
      "outputs": [],
      "source": [
        "# Prepare the target (sectionName) data\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(data_sample['sectionName'])\n",
        "y_train = encoder.transform(train['sectionName'])\n",
        "y_val = encoder.transform(val['sectionName'])\n",
        "y_test = encoder.transform(test['sectionName'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb8GiyW6KaV3",
        "outputId": "424a4d72-3029-4b67-a0ee-530eaabb3c2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "326/326 [==============================] - 73s 201ms/step - loss: 3.3372 - accuracy: 0.0975 - val_loss: 3.2823 - val_accuracy: 0.0867\n",
            "Epoch 2/5\n",
            "326/326 [==============================] - 42s 127ms/step - loss: 3.2110 - accuracy: 0.1256 - val_loss: 3.2360 - val_accuracy: 0.1102\n",
            "Epoch 3/5\n",
            "326/326 [==============================] - 27s 84ms/step - loss: 2.9977 - accuracy: 0.1858 - val_loss: 3.1501 - val_accuracy: 0.1263\n",
            "Epoch 4/5\n",
            "326/326 [==============================] - 22s 67ms/step - loss: 2.6173 - accuracy: 0.2807 - val_loss: 3.0766 - val_accuracy: 0.1458\n",
            "Epoch 5/5\n",
            "326/326 [==============================] - 16s 48ms/step - loss: 2.1613 - accuracy: 0.4016 - val_loss: 2.9679 - val_accuracy: 0.1848\n",
            "Epoch 1/5\n",
            "326/326 [==============================] - 217s 662ms/step - loss: 3.3418 - accuracy: 0.0974 - val_loss: 3.3107 - val_accuracy: 0.0874\n",
            "Epoch 2/5\n",
            "326/326 [==============================] - 203s 623ms/step - loss: 3.1448 - accuracy: 0.1502 - val_loss: 3.3396 - val_accuracy: 0.0867\n",
            "Epoch 3/5\n",
            "326/326 [==============================] - 192s 589ms/step - loss: 2.7943 - accuracy: 0.2763 - val_loss: 3.3403 - val_accuracy: 0.0840\n",
            "Epoch 4/5\n",
            "326/326 [==============================] - 184s 565ms/step - loss: 3.1479 - accuracy: 0.1646 - val_loss: 3.2949 - val_accuracy: 0.0907\n",
            "Epoch 5/5\n",
            "326/326 [==============================] - 182s 558ms/step - loss: 3.0240 - accuracy: 0.2014 - val_loss: 3.3207 - val_accuracy: 0.1028\n",
            "LSTM Test Accuracy: 0.1993277370929718\n",
            "Basic RNN Test Accuracy: 0.09848739206790924\n"
          ]
        }
      ],
      "source": [
        "def build_rnn_model(model_type, state_size):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(len(tokenizer.word_index) + 1, state_size, input_length=max_length))\n",
        "    if model_type == \"LSTM\":\n",
        "        model.add(LSTM(state_size))\n",
        "    elif model_type == \"RNN\":\n",
        "        model.add(SimpleRNN(state_size))\n",
        "    model.add(Dense(len(encoder.classes_), activation=\"softmax\"))\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "# LSTM and RNN have been taken from here \"https://www.tensorflow.org/guide/keras/rnn\"\n",
        "#this included simple rnn and lstm :)\n",
        "\n",
        "# Compare LSTM and Basic RNN models\n",
        "state_size = 128\n",
        "epochs = 5\n",
        "batch_size = 32\n",
        "# I seen people use batch size 32 often I dont know why 32 honestly, when i looked up on google\n",
        "# I found that \"That said, note that for batch size 32 we have the least error rate. We see an exponential increase\n",
        "# in the time taken to train as we move from higher batch size to lower batch size.24 Mar 2022\"\n",
        "# and i chose 10 epochs because 1 takes around 2-3 min\n",
        "# I do not have unlimited time... therefore i chose 10 as it took 49min to train :)\n",
        "\n",
        "# LSTM\n",
        "lstm_model = build_rnn_model(\"LSTM\", state_size)\n",
        "lstm_history = lstm_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size)\n",
        "lstm_test_loss, lstm_test_acc = lstm_model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
        "\n",
        "# RNN\n",
        "rnn_model = build_rnn_model(\"RNN\", state_size)\n",
        "rnn_history = rnn_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size)\n",
        "rnn_test_loss, rnn_test_acc = rnn_model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
        "\n",
        "print(\"LSTM Test Accuracy:\", lstm_test_acc)\n",
        "print(\"Basic RNN Test Accuracy:\", rnn_test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YKUUOTrDPqmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tanl4KR1KgmX",
        "outputId": "6027aca0-041e-4a88-f0d4-b539592e561d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "326/326 [==============================] - 66s 186ms/step - loss: 3.3391 - accuracy: 0.0990 - val_loss: 3.3022 - val_accuracy: 0.0921\n",
            "Epoch 2/5\n",
            "326/326 [==============================] - 40s 123ms/step - loss: 3.2735 - accuracy: 0.1012 - val_loss: 3.2519 - val_accuracy: 0.1082\n",
            "Epoch 3/5\n",
            "326/326 [==============================] - 34s 104ms/step - loss: 3.1622 - accuracy: 0.1327 - val_loss: 3.1707 - val_accuracy: 0.1210\n",
            "Epoch 4/5\n",
            "326/326 [==============================] - 27s 82ms/step - loss: 2.9030 - accuracy: 0.1755 - val_loss: 2.9306 - val_accuracy: 0.1660\n",
            "Epoch 5/5\n",
            "326/326 [==============================] - 25s 77ms/step - loss: 2.8029 - accuracy: 0.1953 - val_loss: 2.9013 - val_accuracy: 0.1680\n",
            "Single-Layer LSTM Test Accuracy: 0.1993277370929718\n",
            "Multi-Layer LSTM Test Accuracy: 0.18689075112342834\n"
          ]
        }
      ],
      "source": [
        "def build_multi_lstm_model(state_size, num_layers):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(len(tokenizer.word_index) + 1, state_size, input_length=max_length))\n",
        "    for _ in range(num_layers - 1):\n",
        "        model.add(LSTM(state_size, return_sequences=True))\n",
        "    model.add(LSTM(state_size))\n",
        "    model.add(Dense(len(encoder.classes_), activation=\"softmax\"))\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "# Compare single-layer and multi-layer LSTM implementations\n",
        "num_layers = 3\n",
        "multi_lstm_model = build_multi_lstm_model(state_size, num_layers)\n",
        "multi_lstm_history = multi_lstm_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=32)\n",
        "multi_lstm_test_loss, multi_lstm_test_acc = multi_lstm_model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(\"Single-Layer LSTM Test Accuracy:\", lstm_test_acc)\n",
        "print(\"Multi-Layer LSTM Test Accuracy:\", multi_lstm_test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "s_YkE2OgWRo2",
        "outputId": "7cad0334-330e-4140-bca2-492c592168e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               sectionName                                        bodyContent\n",
              "97494           World news  Scott Morrison will urge G20 leaders to fund r...\n",
              "69852   Global development  The fragrant jasmine rice growing on the left ...\n",
              "74324              UK news  An MI6 officer was discovered to have child se...\n",
              "51220                Sport  The greatest on-field scandal in the history o...\n",
              "41914             Business  Let’s hope António Horta-Osório is right. The ...\n",
              "...                    ...                                                ...\n",
              "89785              UK news  The jury at Preston crown court has been sent ...\n",
              "83369             Politics  A petition calling on the government not to pr...\n",
              "100105             Opinion  It has been both a curse and a blessing for Ke...\n",
              "139951             Fashion  The opening of Paris haute couture fashion wee...\n",
              "60451           Technology  An advert describing a smartphone app as a “hi...\n",
              "\n",
              "[10410 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0da713ac-81ec-4a80-8a9f-e1a66dba1c1a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sectionName</th>\n",
              "      <th>bodyContent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>97494</th>\n",
              "      <td>World news</td>\n",
              "      <td>Scott Morrison will urge G20 leaders to fund r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69852</th>\n",
              "      <td>Global development</td>\n",
              "      <td>The fragrant jasmine rice growing on the left ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74324</th>\n",
              "      <td>UK news</td>\n",
              "      <td>An MI6 officer was discovered to have child se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51220</th>\n",
              "      <td>Sport</td>\n",
              "      <td>The greatest on-field scandal in the history o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41914</th>\n",
              "      <td>Business</td>\n",
              "      <td>Let’s hope António Horta-Osório is right. The ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89785</th>\n",
              "      <td>UK news</td>\n",
              "      <td>The jury at Preston crown court has been sent ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83369</th>\n",
              "      <td>Politics</td>\n",
              "      <td>A petition calling on the government not to pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100105</th>\n",
              "      <td>Opinion</td>\n",
              "      <td>It has been both a curse and a blessing for Ke...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139951</th>\n",
              "      <td>Fashion</td>\n",
              "      <td>The opening of Paris haute couture fashion wee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60451</th>\n",
              "      <td>Technology</td>\n",
              "      <td>An advert describing a smartphone app as a “hi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10410 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0da713ac-81ec-4a80-8a9f-e1a66dba1c1a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0da713ac-81ec-4a80-8a9f-e1a66dba1c1a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0da713ac-81ec-4a80-8a9f-e1a66dba1c1a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIWuOWIGKiKq",
        "outputId": "3d5cc3ad-6fb3-40c4-ecfa-c6eec3cc6d4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading pre-trained embeddings: load() got an unexpected keyword argument 'ssl_context'\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_hub as hub\n",
        "import ssl\n",
        "\n",
        "# Load pre-trained word embeddings\n",
        "try:\n",
        "    ctx = ssl.create_default_context()\n",
        "    ctx.check_hostname = False\n",
        "    ctx.verify_mode = ssl.CERT_NONE\n",
        "\n",
        "    embed = hub.load(\"https://tfhub.dev/google/nnlm-en-dim128/2\", ssl_context=ctx)\n",
        "    embeddings_layer = hub.KerasLayer(embed, input_shape=[], dtype=tf.string, trainable=True)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error loading pre-trained embeddings:\", e)\n",
        "    embeddings_layer = None\n",
        "\n",
        "# Preprocess text data for pre-trained embeddings\n",
        "X_train_str = train['bodyContent'].values\n",
        "X_val_str = val['bodyContent'].values\n",
        "X_test_str = test['bodyContent'].values\n",
        "\n",
        "# Build and compile the embedding model\n",
        "def build_embedding_model(use_pretrained_embeddings):\n",
        "    model = tf.keras.Sequential()\n",
        "    if use_pretrained_embeddings and embeddings_layer is not None:\n",
        "        model.add(embeddings_layer)\n",
        "    else:\n",
        "        model.add(tf.keras.layers.Embedding(len(tokenizer.word_index) + 1, state_size, input_length=max_length))\n",
        "    model.add(tf.keras.layers.LSTM(state_size))\n",
        "    model.add(tf.keras.layers.Dense(len(encoder.classes_), activation=\"softmax\"))\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aY_sUd8RRa8P"
      },
      "source": [
        "# Compare classification between embeddings learned on the fly and pre-trained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbpmwjbNRHTf",
        "outputId": "b42fee22-1325-4f76-e1ed-f063516ba3f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "326/326 [==============================] - 53s 156ms/step - loss: 3.3435 - accuracy: 0.0963 - val_loss: 3.2814 - val_accuracy: 0.0887\n",
            "Epoch 2/5\n",
            "326/326 [==============================] - 31s 94ms/step - loss: 3.2318 - accuracy: 0.1067 - val_loss: 3.2771 - val_accuracy: 0.0934\n",
            "Epoch 3/5\n",
            "326/326 [==============================] - 21s 66ms/step - loss: 3.0472 - accuracy: 0.1744 - val_loss: 3.1652 - val_accuracy: 0.1290\n",
            "Epoch 4/5\n",
            "326/326 [==============================] - 17s 51ms/step - loss: 2.6472 - accuracy: 0.2767 - val_loss: 2.9980 - val_accuracy: 0.1687\n",
            "Epoch 5/5\n",
            "326/326 [==============================] - 16s 48ms/step - loss: 2.1523 - accuracy: 0.4061 - val_loss: 3.1346 - val_accuracy: 0.1633\n"
          ]
        }
      ],
      "source": [
        "# Embeddings learned on the fly\n",
        "embedding_model_fly = build_embedding_model(False)\n",
        "embedding_fly_history = embedding_model_fly.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=32)\n",
        "embedding_fly_test_loss, embedding_fly_test_acc = embedding_model_fly.evaluate(X_test, y_test, verbose=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNBzrmffRXML",
        "outputId": "5afa6310-1912-407e-9e2c-98fc5e4b2206"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "326/326 [==============================] - 51s 150ms/step - loss: 3.3427 - accuracy: 0.0990 - val_loss: 3.2711 - val_accuracy: 0.0921\n",
            "Epoch 2/5\n",
            "326/326 [==============================] - 30s 92ms/step - loss: 3.2248 - accuracy: 0.1178 - val_loss: 3.2891 - val_accuracy: 0.0907\n",
            "Epoch 3/5\n",
            "326/326 [==============================] - 24s 74ms/step - loss: 3.0787 - accuracy: 0.1768 - val_loss: 3.2722 - val_accuracy: 0.0981\n",
            "Epoch 4/5\n",
            "326/326 [==============================] - 15s 46ms/step - loss: 2.6461 - accuracy: 0.3029 - val_loss: 3.1986 - val_accuracy: 0.1526\n",
            "Epoch 5/5\n",
            "326/326 [==============================] - 14s 43ms/step - loss: 2.1105 - accuracy: 0.4439 - val_loss: 3.2966 - val_accuracy: 0.1599\n"
          ]
        }
      ],
      "source": [
        "# Pre-trained word embeddings\n",
        "embedding_model_pretrained = build_embedding_model(True)\n",
        "embedding_pretrained_history = embedding_model_pretrained.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=32)\n",
        "embedding_pretrained_test_loss, embedding_pretrained_test_acc = embedding_model_pretrained.evaluate(X_test, y_test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjtPAKF7RZG1",
        "outputId": "aee0833a-6e1b-4dff-b4e7-7f44f20e378c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings learned on the fly Test Accuracy: 0.16974790394306183\n",
            "Pre-trained word embeddings Test Accuracy: 0.16840335726737976\n"
          ]
        }
      ],
      "source": [
        "print(\"Embeddings learned on the fly Test Accuracy:\", embedding_fly_test_acc)\n",
        "print(\"Pre-trained word embeddings Test Accuracy:\", embedding_pretrained_test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "X2hW7kc3gLML",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a92b01a7-f3a1-4a28-ff01-c5d279a5d679"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "326/326 [==============================] - 52s 154ms/step - loss: 3.3385 - accuracy: 0.0982 - val_loss: 3.2808 - val_accuracy: 0.0921\n",
            "Epoch 2/5\n",
            "326/326 [==============================] - 30s 93ms/step - loss: 3.2077 - accuracy: 0.1147 - val_loss: 3.2120 - val_accuracy: 0.1169\n",
            "Epoch 3/5\n",
            "326/326 [==============================] - 23s 70ms/step - loss: 3.1499 - accuracy: 0.1420 - val_loss: 3.2657 - val_accuracy: 0.0867\n",
            "Epoch 4/5\n",
            "326/326 [==============================] - 18s 56ms/step - loss: 2.9488 - accuracy: 0.2039 - val_loss: 2.9519 - val_accuracy: 0.1620\n",
            "Epoch 5/5\n",
            "326/326 [==============================] - 17s 53ms/step - loss: 2.5577 - accuracy: 0.3142 - val_loss: 3.2328 - val_accuracy: 0.1142\n",
            "Epoch 1/5\n",
            "326/326 [==============================] - 54s 147ms/step - loss: 3.3236 - accuracy: 0.0999 - val_loss: 3.2853 - val_accuracy: 0.0921\n",
            "Epoch 2/5\n",
            "326/326 [==============================] - 30s 91ms/step - loss: 3.0891 - accuracy: 0.1420 - val_loss: 2.9389 - val_accuracy: 0.1552\n",
            "Epoch 3/5\n",
            "326/326 [==============================] - 21s 65ms/step - loss: 2.7114 - accuracy: 0.2384 - val_loss: 2.9474 - val_accuracy: 0.1532\n",
            "Epoch 4/5\n",
            "326/326 [==============================] - 15s 46ms/step - loss: 2.2808 - accuracy: 0.3567 - val_loss: 2.8679 - val_accuracy: 0.2063\n",
            "Epoch 5/5\n",
            "326/326 [==============================] - 12s 37ms/step - loss: 1.9490 - accuracy: 0.4506 - val_loss: 2.9142 - val_accuracy: 0.1969\n",
            "CNN as an alternative to LSTM Test Accuracy: 0.1297478973865509\n",
            "CNN as an additional layer before LSTM Test Accuracy: 0.21647058427333832\n"
          ]
        }
      ],
      "source": [
        "def build_cnn_model(use_cnn_before_lstm):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(len(tokenizer.word_index) + 1, state_size, input_length=max_length))\n",
        "    if use_cnn_before_lstm:\n",
        "        model.add(Conv1D(filters=64, kernel_size=3, activation=\"relu\"))\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(LSTM(state_size))\n",
        "    model.add(Dense(len(encoder.classes_), activation=\"softmax\"))\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "# Use of CNN as an alternative to LSTM\n",
        "cnn_model = build_cnn_model(False)\n",
        "cnn_history = cnn_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=32)\n",
        "cnn_test_loss, cnn_test_acc = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "# Use of CNN as an additional layer before LSTM\n",
        "cnn_lstm_model = build_cnn_model(True)\n",
        "cnn_lstm_history = cnn_lstm_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=32)\n",
        "cnn_lstm_test_loss, cnn_lstm_test_acc = cnn_lstm_model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(\"CNN as an alternative to LSTM Test Accuracy:\", cnn_test_acc)\n",
        "print(\"CNN as an additional layer before LSTM Test Accuracy:\", cnn_lstm_test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "z-QXRgPkgpEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa245509-64be-4cfc-d111-4c978a0e6d20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Neural Model Test Accuracy: 0.21647058427333832\n",
            "Naive Bayes Test Accuracy: 0.26857142857142857\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Compare the performance of the best performing neural model against Naive Bayes\n",
        "vectorizer = TfidfVectorizer()\n",
        "clf = MultinomialNB()\n",
        "\n",
        "text_clf = make_pipeline(vectorizer, clf)\n",
        "text_clf.fit(train['bodyContent'], y_train)\n",
        "naive_bayes_test_acc = text_clf.score(test['bodyContent'], y_test)\n",
        "\n",
        "best_neural_acc = max([lstm_test_acc, rnn_test_acc, multi_lstm_test_acc, embedding_fly_test_acc, embedding_pretrained_test_acc, cnn_test_acc, cnn_lstm_test_acc])\n",
        "\n",
        "\n",
        "print(\"Best Neural Model Test Accuracy:\", best_neural_acc)\n",
        "print(\"Naive Bayes Test Accuracy:\", naive_bayes_test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "AkhPk5LAgzWG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49a7caf1-86fc-4062-8c81-cf0b0ea1dae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 10410\n",
            "Validation samples: 1488\n",
            "Test samples: 2975\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data_2 = pd.read_csv('/content/guardian_articles.csv')\n",
        "# Select a random 10%-20% portion of the dataset\n",
        "data_2 = data_2[['bodyContent', 'webTitle']]  # Keep only the relevant columns\n",
        "data_2 = data_2.dropna()  # Remove rows with missing values\n",
        "\n",
        "data_sample_2 = data_2.sample(frac=0.1, random_state=42)\n",
        "\n",
        "# Split the dataset into training (80%), validation (10%), and test (10%) sets\n",
        "train_2, test_2 = train_test_split(data_sample_2, test_size=0.2, random_state=42)\n",
        "train_2, val_2 = train_test_split(train_2, test_size=0.125, random_state=42)\n",
        "\n",
        "print(\"Training samples:\", len(train_2))\n",
        "print(\"Validation samples:\", len(val_2))\n",
        "print(\"Test samples:\", len(test_2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_e36EBLg6zV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "666e2bca-0d48-49f9-f003-e85963bd77c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "326/326 [==============================] - 51s 148ms/step - loss: 3.3089 - accuracy: 0.1216 - val_loss: 3.1750 - val_accuracy: 0.1472\n",
            "Epoch 2/5\n",
            "326/326 [==============================] - 32s 98ms/step - loss: 2.8004 - accuracy: 0.2529 - val_loss: 2.6947 - val_accuracy: 0.2708\n",
            "Epoch 3/5\n",
            "304/326 [==========================>...] - ETA: 5s - loss: 2.1653 - accuracy: 0.4168"
          ]
        }
      ],
      "source": [
        "# Build a model that uses both the text of an article and the web title to predict the section heading\n",
        "X_train_both = train_2['bodyContent'] + ' ' + train_2['webTitle']\n",
        "X_val_both = val_2['bodyContent'] + ' ' + val_2['webTitle']\n",
        "X_test_both = test_2['bodyContent'] + ' ' + test_2['webTitle']\n",
        "\n",
        "# Tokenize the combined text and title data\n",
        "X_train_both = tokenizer.texts_to_sequences(X_train_both)\n",
        "X_val_both = tokenizer.texts_to_sequences(X_val_both)\n",
        "X_test_both = tokenizer.texts_to_sequences(X_test_both)\n",
        "\n",
        "# Pad the sequences\n",
        "X_train_both = pad_sequences(X_train_both, maxlen=max_length, padding=\"post\")\n",
        "X_val_both = pad_sequences(X_val_both, maxlen=max_length, padding=\"post\")\n",
        "X_test_both = pad_sequences(X_test_both, maxlen=max_length, padding=\"post\")\n",
        "\n",
        "# Train model with both text and title data\n",
        "both_model = build_rnn_model(\"LSTM\", state_size)\n",
        "both_history = both_model.fit(X_train_both, y_train, validation_data=(X_val_both, y_val), epochs=epochs, batch_size=32)\n",
        "both_test_loss, both_test_acc = both_model.evaluate(X_test_both, y_test, verbose=0)\n",
        "\n",
        "print(\"Model with both text and web title Test Accuracy:\", both_test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9doQFQbgg8gN"
      },
      "outputs": [],
      "source": [
        "# Save two models: the best model obtained without pre-trained embeddings and the best model obtained with pre-trained embeddings\n",
        "models = {\n",
        "    \"lstm\": lstm_test_acc,\n",
        "    \"rnn\": rnn_test_acc,\n",
        "    \"multi_lstm\": multi_lstm_test_acc,\n",
        "    \"embedding_fly\": embedding_fly_test_acc,\n",
        "    \"embedding_pretrained\": embedding_pretrained_test_acc,\n",
        "    \"cnn\": cnn_test_acc,\n",
        "    \"cnn_lstm\": cnn_lstm_test_acc,\n",
        "    \"both\": both_test_acc\n",
        "}\n",
        "\n",
        "best_model_no_pretrained = max(models, key=lambda x: models[x] if x != \"embedding_pretrained\" else -1)\n",
        "best_model_pretrained = \"embedding_pretrained\"\n",
        "\n",
        "# Save the best models\n",
        "lstm_model.save(f\"best_model_no_pretrained_{best_model_no_pretrained}.h5\")\n",
        "embedding_model_pretrained.save(\"best_model_pretrained_embedding.h5\")\n",
        "\n",
        "print(f\"Best model without pre-trained embeddings: {best_model_no_pretrained}.h5\")\n",
        "print(\"Best model with pre-trained embeddings: best_model_pretrained_embedding.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_model(model, X_train, y_train, X_val, y_val, epochs, batch_size):\n",
        "    # Set up early stopping to prevent overfitting\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "    \n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\n",
        "    \n",
        "    # Evaluate the model\n",
        "    train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
        "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "    \n",
        "    print(f'Training accuracy: {train_acc:.4f}, Validation accuracy: {val_acc:.4f}')\n",
        "    print(f'Training loss: {train_loss:.4f}, Validation loss: {val_loss:.4f}')\n",
        "    \n",
        "    return history"
      ],
      "metadata": {
        "id": "BTV7gByrPFJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvKOBbkd1EWa"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(history):\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "# Load the saved models\n",
        "best_model_no_pretrained = load_model('/content/best_model_no_pretrained_both.h5')\n",
        "best_model_pretrained = load_model('/content/best_model_pretrained_embedding.h5')\n",
        "\n",
        "# Train and evaluate the model without pre-trained embeddings\n",
        "history_no_pretrained = train_and_evaluate_model(best_model_no_pretrained, X_train, y_train, X_val, y_val, epochs=5, batch_size=32)\n",
        "plot_history(history_no_pretrained)\n",
        "\n",
        "# Train and evaluate the model with pre-trained embeddings\n",
        "history_pretrained = train_and_evaluate_model(best_model_pretrained, X_train, y_train, X_val, y_val, epochs=5, batch_size=32)\n",
        "plot_history(history_pretrained)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}